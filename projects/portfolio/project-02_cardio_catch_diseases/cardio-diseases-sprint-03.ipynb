{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floral-torture",
   "metadata": {},
   "source": [
    "### **D2APR: Aprendizado de M√°quina e Reconhecimento de Padr√µes** (IFSP, Campinas) <br/>\n",
    "**Prof**: Samuel Martins (Samuka) <br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. <br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-structure",
   "metadata": {},
   "source": [
    "#### Custom CSS style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-relation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".dashed-box {\n",
    "    border: 1px dashed black !important;\n",
    "#    font-size: var(--jp-content-font-size1) !important;\n",
    "}\n",
    "\n",
    ".dashed-box table {\n",
    "\n",
    "}\n",
    "\n",
    ".dashed-box tr {\n",
    "    background-color: white !important;\n",
    "}\n",
    "        \n",
    ".alt-tab {\n",
    "    background-color: black;\n",
    "    color: #ffc351;\n",
    "    padding: 4px;\n",
    "    font-size: 1em;\n",
    "    font-weight: bold;\n",
    "    font-family: monospace;\n",
    "}\n",
    "// add your CSS styling here\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-abraham",
   "metadata": {},
   "source": [
    "<span style='font-size: 2.5em'><b>Cardiovascular Disease üíî</b></span><br/>\n",
    "<span style='font-size: 1.5em'>Predict cardiovascular diseases</span>\n",
    "\n",
    "<span style=\"background-color: #ffc351; padding: 4px; font-size: 1em;\"><b>Sprint #3</b></span>\n",
    "\n",
    "<img src=\"./imgs/cardio.png\" width=300/>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-cabin",
   "metadata": {},
   "source": [
    "## Before starting this notebook\n",
    "This jupyter notebook is designed for **experimental and teaching purposes**. <br/>\n",
    "Although it is (relatively) well organized, it aims at solving the _target problem_ by evaluating (and documenting) _different solutions_ for somes steps of the **machine learning pipeline** ‚Äî see the [***Machine Learning Project Checklist by xavecoding***](https://github.com/xavecoding/IFSP-CMP-D2APR-2021.2/blob/main/cheat-sheets/machine-learning-project-checklist_by_xavecoding.pdf). <br/>\n",
    "We tried to make this notebook as literally a _notebook_. Thus, it contains notes, drafts, comments, etc.<br/>\n",
    "\n",
    "For teaching purposes, some parts of the notebook may be _overcommented_. Moreover, to simulate a real development scenario, we will divide our solution and experiments into **\"sprints\"** in which each sprint has some goals (e.g., perform _feature selection_, train more ML models, ...). <br/>\n",
    "The **sprint goal** will be stated at the beginning of the notebook.\n",
    "\n",
    "A ***final notebook*** (or any other kind of presentation) that compiles and summarizes all sprints ‚Äî the target problem, solutions, and findings ‚Äî should be created later.\n",
    "\n",
    "#### Conventions\n",
    "\n",
    "<ul>\n",
    "    <li>üí° indicates a tip. </li>\n",
    "    <li> ‚ö†Ô∏è indicates a warning message. </li>\n",
    "    <li><span class='alt-tab'>alt tab</span> indicates and an extra content (<i>e.g.</i>, slides) to explain a given concept.</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-wisconsin",
   "metadata": {},
   "source": [
    "## üéØ Sprint Goals\n",
    "- Evaluate on the training set: different strategies/versions of Naive Bayes:\n",
    "  + Strategy #1 - Gaussian Naive Bayes with only numerical features\n",
    "  + Strategy #2 - Categorical Naive Bayes with only categorical features\n",
    "  + Strategy #3 - Categorical Naive Bayes after converting numerical features to categorical\n",
    "  + Strategy #4 - Mixed Naive Bayes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-printing",
   "metadata": {},
   "source": [
    "### 0. Imports and default settings for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-beginning",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 5. Prepare the Data\n",
    "\n",
    "Each strategy for Naive Bayes will require a specific preprocessing pipeline. So, let's skip this section and create a full pipeline with preprocessing and classifiers for each version.\n",
    "\n",
    "**Preprocessing tasks**\n",
    "- Fill in missing values (imputation)\n",
    "- Add new features\n",
    "- Feature Scaling\n",
    "- One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-muslim",
   "metadata": {},
   "source": [
    "### 5.1. Load the cleaned training set\n",
    "Let's consider the training and testing sets already cleaned (Sprint #1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_train = pd.read_csv('./datasets/cardio_clean_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to remember what categorical variables are like\n",
    "for cat_attribute in ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']:\n",
    "    print(cardio_train[cat_attribute].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-bible",
   "metadata": {},
   "source": [
    "### 5.2. Separate the features and the classes (target outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the target outcome into a numpy array\n",
    "y_train = cardio_train['cardio'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the dataframe with only the features  \n",
    "cardio_train = cardio_train.drop(columns=['cardio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41521716-6899-4249-884e-ba912ab865b3",
   "metadata": {},
   "source": [
    "### üèãÔ∏è‚Äç‚ôÄÔ∏è 6. Train ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08bd82-40ce-4125-b285-212ad272f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical variables\n",
    "num_vars = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "\n",
    "# categorical binary variables\n",
    "bin_vars = ['gender', 'smoke', 'alco', 'active']\n",
    "\n",
    "# categorical variables\n",
    "cat_vars = ['cholesterol', 'gluc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a82799-4e94-49d1-ba2c-bbe1d153e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "## separating the features into specific dataset according to their type\n",
    "cardio_train_num = cardio_train[num_vars]\n",
    "cardio_train_bin = cardio_train[bin_vars]\n",
    "cardio_train_cat = cardio_train[cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33551059-f655-449c-a7ee-5986672fe8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# printing function\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"\\nMean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed5a0e8-d789-4b08-952a-b213a010ee5a",
   "metadata": {},
   "source": [
    "### **6.1. Strategy #1 - Gaussian Naive Bayes with only numerical features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9971afa-648d-4074-895b-4473370f5238",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7bf448-483c-439d-934d-17800b70f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### numerical preprocessing pipeline\n",
    "num_preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('robust_scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "\n",
    "### complete preprocessing pipeline\n",
    "# in this case, we are using it just to filter the desired columns automatically during the full pipeline.\n",
    "# one could do this manually outside the pipeline\n",
    "preprocessing_pipeline_1 = ColumnTransformer([\n",
    "    ('numerical_preprocessing', num_preprocessing_pipeline, num_vars)\n",
    "])\n",
    "\n",
    "\n",
    "### naive bayes model = preprocessing + naive bayes classifier\n",
    "naive_bayes_1 = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline_1),\n",
    "    ('naive_bayes', GaussianNB())\n",
    "])\n",
    "\n",
    "\n",
    "### training naive bayes\n",
    "naive_bayes_1.fit(cardio_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a8892-ccbe-48a5-b772-2d590292b7bb",
   "metadata": {},
   "source": [
    "#### **Validation on Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe5690-309a-4d9b-87de-8bb1a597fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_1_accs = cross_val_score(naive_bayes_1, cardio_train, y_train, scoring=\"accuracy\", cv=10)\n",
    "display_scores(naive_bayes_1_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e32d6-6bc6-4f8e-b6b6-ad0ccaa24719",
   "metadata": {},
   "source": [
    "### **6.2. Strategy #2 - Categorical Naive Bayes with only categorical features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76d5dc-cd9f-4f17-9bfa-8bebb267c89c",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2680e-bf91-41eb-8bde-215d18f29171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### categorical preprocessing pipeline\n",
    "# there will not be OneHotEncoder because the CategoricalNB expects ordinal labels (0, 1, 2, 3, ...)\n",
    "cat_preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))  # as the categories are numbers, we can use the SimpleImputer\n",
    "])\n",
    "\n",
    "\n",
    "### complete preprocessing pipeline\n",
    "# in this case, we are using it just to filter the desired columns automatically during the full pipeline.\n",
    "# one could do this manually outside the pipeline\n",
    "preprocessing_pipeline_2 = ColumnTransformer([\n",
    "    ('categorical_preprocessing', cat_preprocessing_pipeline, cat_vars)\n",
    "])\n",
    "\n",
    "\n",
    "### naive bayes model = preprocessing + naive bayes classifier\n",
    "naive_bayes_2 = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline_2),\n",
    "    ('naive_bayes', CategoricalNB())\n",
    "])\n",
    "\n",
    "\n",
    "### training naive bayes\n",
    "naive_bayes_2.fit(cardio_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722dbb5-73b6-40e2-b956-6b809d1a49e2",
   "metadata": {},
   "source": [
    "#### **Validation on Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcad91d-eab5-4fda-8645-13d92ebf4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_2_accs = cross_val_score(naive_bayes_2, cardio_train, y_train, scoring=\"accuracy\", cv=10)\n",
    "display_scores(naive_bayes_2_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2731d9-c495-454f-b465-6305069b594a",
   "metadata": {},
   "source": [
    "### **6.3. Strategy #3 - Categorical Naive Bayes after converting numerical features to categorical**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0134d-f408-41a9-854b-1acb98722208",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4351b6-ab12-458e-a321-4644c65a3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### numerical preprocessing pipeline\n",
    "# we are using 10 bins but this hyperparameter could be optimized,\n",
    "# the same for the strategy\n",
    "num_preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('discretization', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform'))\n",
    "])\n",
    "\n",
    "\n",
    "### categorical preprocessing pipeline\n",
    "# there will not be OneHotEncoder because the CategoricalNB expects ordinal labels (0, 1, 2, 3, ...)\n",
    "cat_preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))  # as the categories are numbers, we can use the SimpleImputer\n",
    "])\n",
    "\n",
    "\n",
    "### complete preprocessing pipeline\n",
    "# in this case, we are using it just to filter the desired columns automatically during the full pipeline.\n",
    "# one could do this manually outside the pipeline\n",
    "preprocessing_pipeline_3 = ColumnTransformer([\n",
    "    ('numerical_preprocessing', num_preprocessing_pipeline, num_vars),\n",
    "    ('categorical_preprocessing', cat_preprocessing_pipeline, cat_vars)\n",
    "])\n",
    "\n",
    "\n",
    "### naive bayes model = preprocessing + naive bayes classifier\n",
    "naive_bayes_3 = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline_3),\n",
    "    ('naive_bayes', CategoricalNB())\n",
    "])\n",
    "\n",
    "\n",
    "### training naive bayes\n",
    "naive_bayes_3.fit(cardio_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde49364-08c6-4276-94d4-6ac752f89782",
   "metadata": {},
   "source": [
    "#### **Validation on Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0dc6c7-e6ca-4e77-8aae-7073a787c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_3_accs = cross_val_score(naive_bayes_3, cardio_train, y_train, scoring=\"accuracy\", cv=10)\n",
    "display_scores(naive_bayes_3_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361f840-fdbd-4b21-8f94-0b9ab89b6fd6",
   "metadata": {},
   "source": [
    "### **6.4 Strategy #4 - Mixed Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4611bc-a8b2-4fc0-a427-a0e14974853e",
   "metadata": {},
   "source": [
    "pip install mixed-naive-bayes <br/>\n",
    "https://github.com/remykarem/mixed-naive-bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dad9d-86fb-4ce7-8393-be745405a2ae",
   "metadata": {},
   "source": [
    "`Mixed Naive Bayes` allows us to use Naive Bayes with _continuous_ and _discrete/categorical data_. <br/>\n",
    "For that, we need to specify the indices of all categorical features (including the binary ones).\n",
    "\n",
    "When using `ColumnTransformer` to concatenate preprocessing pipelines, the **order of each pipeline** will result the order of their corresponding features in the final preprocessed data. <br/>\n",
    "Let's consider that the order of the preprocessing pipelines will be: **continuous** and then **discrite/categorical**. <br/>\n",
    "As our pipelines do not create any new feature, the final order will be:\n",
    "\n",
    "\n",
    "[0] 'age', [1] 'height', [2] 'weight', [3] 'ap_hi', [4] 'ap_lo' <br/>\n",
    "and then <br/>\n",
    "[5] 'gender', [6] 'smoke', [7] 'alco', [8] 'active', [9] 'cholesterol', [10] 'gluc'\n",
    "\n",
    "Therefore, the categorical features are those with indices from 5 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946fdb6-72ce-4f69-95a4-66b98e2041ba",
   "metadata": {},
   "source": [
    "#### **Training - NOT WORKING... I NEED TO REVIEW IT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ceb4b-2c18-4fbb-ace0-d24086fb206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mixed_naive_bayes import MixedNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### numerical preprocessing pipeline\n",
    "num_preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('robust_scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "\n",
    "### categorical preprocessing pipeline\n",
    "bin_preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))  # as the categories are numbers, we can use the SimpleImputer\n",
    "])\n",
    "\n",
    "\n",
    "### categorical preprocessing pipeline\n",
    "# there will not be OneHotEncoder because the CategoricalNB expects ordinal labels (0, 1, 2, 3, ...)\n",
    "cat_preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # as the categories are numbers, we can use the SimpleImputer\n",
    "])\n",
    "\n",
    "\n",
    "### complete preprocessing pipeline\n",
    "# in this case, we are using it just to filter the desired columns automatically during the full pipeline.\n",
    "# one could do this manually outside the pipeline\n",
    "preprocessing_pipeline_4 = ColumnTransformer([\n",
    "    ('numerical_preprocessing', num_preprocessing_pipeline, num_vars),\n",
    "    ('bin_preprocessing', bin_preprocessing_pipeline, bin_vars),\n",
    "    ('categorical_preprocessing', cat_preprocessing_pipeline, cat_vars)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "categorical_features_indices = list(range(5, 11))\n",
    "\n",
    "\n",
    "### naive bayes model = preprocessing + naive bayes classifier\n",
    "naive_bayes_4 = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline_4),\n",
    "    ('naive_bayes', MixedNB(categorical_features=categorical_features_indices))\n",
    "])\n",
    "\n",
    "\n",
    "### training naive bayes\n",
    "naive_bayes_4.fit(cardio_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dffbb5-e313-45d2-86bb-419c838346c6",
   "metadata": {},
   "source": [
    "#### **Validation on Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de3ae0-afcb-4001-9c0e-c8ec7fe7336c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-feature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
